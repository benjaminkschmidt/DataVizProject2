{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo Do: \\n    city Maps\\n    state maps-categories, salary, \\n    clean up charts-\\n    To DO Analysis\\n    To Do NLP on job description-done\\n    csv to github-\\n    comments-\\n    salary ranges\\n    \\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To Do: \n",
    "    city Maps\n",
    "    state maps-categories, salary, \n",
    "    clean up charts-\n",
    "    To DO Analysis\n",
    "    To Do NLP on job description-done\n",
    "    csv to github-\n",
    "    comments-\n",
    "    salary ranges\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import sklearn as sk\n",
    "#https://medium.com/@erikgreenj/mapping-us-states-with-geopandas-made-simple-d7b6e66fa20d\n",
    "import csv\n",
    "import spacy\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crawl_timestamp  \\\n",
      "0  2019-02-06 05:26:22 +0000   \n",
      "1  2019-02-06 05:33:41 +0000   \n",
      "2  2019-02-06 05:33:35 +0000   \n",
      "3  2019-02-06 05:33:42 +0000   \n",
      "4  2019-02-06 05:48:23 +0000   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.indeed.com/viewjob?jk=fd83355c2b23...   \n",
      "1  https://www.dice.com/jobs/detail/Data-Scientis...   \n",
      "2  https://www.dice.com/jobs/detail/Data-Scientis...   \n",
      "3  https://www.indeed.com/viewjob?jk=841edd86ead2...   \n",
      "4  https://job-openings.monster.com/senior-data-s...   \n",
      "\n",
      "                                           job_title            category  \\\n",
      "0                        Enterprise Data Scientist I  Accounting/Finance   \n",
      "1                                     Data Scientist                 NaN   \n",
      "2                                     Data Scientist                 NaN   \n",
      "3  Data Scientist, Aladdin Wealth Tech, Associate...  Accounting/Finance   \n",
      "4                              Senior Data Scientist             biotech   \n",
      "\n",
      "                           company_name            city  \\\n",
      "0               Farmers Insurance Group  Woodland Hills   \n",
      "1                        Luxoft USA Inc      Middletown   \n",
      "2  Cincinnati Bell Technology Solutions        New York   \n",
      "3                             BlackRock        New York   \n",
      "4                           CyberCoders       Charlotte   \n",
      "\n",
      "                     state country   inferred_city  inferred_state  \\\n",
      "0                       CA     Usa  Woodland hills      California   \n",
      "1                       NJ     Usa      Middletown      New jersey   \n",
      "2                       NY     Usa        New york        New york   \n",
      "3  NY 10055 (Midtown area)     Usa        New york        New york   \n",
      "4                       NC     Usa       Charlotte  North carolina   \n",
      "\n",
      "          ...                                             job_description  \\\n",
      "0         ...           Read what people are saying about working here...   \n",
      "1         ...           We have an immediate opening for a Sharp Data ...   \n",
      "2         ...           Candidates should have the following backgroun...   \n",
      "3         ...           Read what people are saying about working here...   \n",
      "4         ...           We are seeking an extraordinary Data Scientist...   \n",
      "\n",
      "    job_type salary_offered job_board  geo            cursor contact_email  \\\n",
      "0  Undefined            NaN    indeed  usa  1549432819114777           NaN   \n",
      "1  Undefined            NaN      dice  usa  1549432819122106           NaN   \n",
      "2  Full Time            NaN      dice  usa  1549432819236156           NaN   \n",
      "3  Undefined            NaN    indeed  usa  1549432819259473           NaN   \n",
      "4  Full Time            NaN   monster  usa  1549436429015957           NaN   \n",
      "\n",
      "   contact_phone_number                           uniq_id html_job_description  \n",
      "0                   NaN  3b6c6acfcba6135a31c83bd7ea493b18                  NaN  \n",
      "1                   NaN  741727428839ae7ada852eebef29b0fe                  NaN  \n",
      "2                   NaN  cdc9ef9a1de327ccdc19cc0d07dbbb37                  NaN  \n",
      "3                   NaN  1c8541cd2c2c924f9391c7d3f526f64e                  NaN  \n",
      "4                   NaN  445652a560a5441060857853cf267470                  NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "crawl_timestamp\n",
      "url\n",
      "job_title\n",
      "category\n",
      "company_name\n",
      "city\n",
      "state\n",
      "country\n",
      "inferred_city\n",
      "inferred_state\n",
      "inferred_country\n",
      "post_date\n",
      "job_description\n",
      "job_type\n",
      "salary_offered\n",
      "job_board\n",
      "geo\n",
      "cursor\n",
      "contact_email\n",
      "contact_phone_number\n",
      "uniq_id\n",
      "html_job_description\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "#put on a github\n",
    "data = pd.read_csv(\"data_scientist_united_states_job_postings_jobspikr.csv\")\n",
    "#data = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_us_cities.csv')\n",
    "\n",
    "print(data.head())\n",
    "for col in data.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'city'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8a2b9816396e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"long\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"city\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"state\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mget_lt_long\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.2\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3118\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'city'"
     ]
    }
   ],
   "source": [
    "#eda\n",
    "#add geo tag\n",
    "from geopy import geocoders\n",
    "gn = geocoders.GeoNames(username=\"bkschmidt\")\n",
    "def get_lt_long(city, state):\n",
    "    output=gn.geocode(city, state)[0]\n",
    "    data[\"lat\"]=output[1][0]\n",
    "    data[\"long\"]=output[1][1]\n",
    "for row in data:\n",
    "    city=data[row][\"city\"]\n",
    "    state=data[row][\"state\"]\n",
    "    get_lt_long(city, state)\n",
    "print(data[\"lat\",\"long\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up dataset\n",
    "data['job_title'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['company_name'].value_counts()\n",
    "#data['company_name'].nlargest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['salary_offered'].value_counts()\n",
    "#clean salary: \n",
    "for i in data[\"salary_offered\"]:\n",
    "    if i = \"$80K - $100K \":\n",
    "        i=80000\n",
    "    if i =\"$100K - $150K\":\n",
    "        i=100000\n",
    "    if i== \"$150K - $200K\":\n",
    "        i=150000\n",
    "    if i ==\"$200K - $250K\":\n",
    "        i=200000\n",
    "    if i== \"$85k - 97k | Equity\":\n",
    "        i= 85000\n",
    "    if i == \"$150k - 175k | Equity\":\n",
    "        i= 150000\n",
    "    if i = \"$80K - $150K\":\n",
    "        i= 80000\n",
    "    if i ==\"$100k - 135k | Equity\":\n",
    "        i=100000\n",
    "    if i == \"$50k - 75k | Equity\":                        \n",
    "        i=50000\n",
    "    if i ==\"$250K - $500K\":\n",
    "        i= 250000\n",
    "    if i == \"$200K - $2147484K\":\n",
    "        i = 200000\n",
    "    else:\n",
    "        i=0\n",
    "data['salary_offered'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description analysis, pull out languages and skill analysis adjust this to tak in the count of each\n",
    "stop_words = set(stopwords.words('english')) \n",
    "skills=[\"python\", \"java\", \"machine learning\", \"ml\", \"sql\", \"nosql\", \"deep learning\", \"r\", \"aws\", \"azure\", \"statistics\", \"phd\", \"pandas\", \"sklearn\", \"javascript\", \"d3j\", \"powerbi\", \"excel\", \"tableau\", \"visualization\", \"big data\", \"hadoop\", \"spark\"]\n",
    "skills_list=[]\n",
    "for description in data['job_description']:\n",
    "  \n",
    "    word_tokens = word_tokenize(description.lower()) \n",
    "  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    for i in skills:\n",
    "    \n",
    "        skills=[w for w in filtered_sentence if w in i]\n",
    "    skillcount=len(skills)\n",
    "    skills_list.append(skillscount)\n",
    "    #print(\"working\")\n",
    "    \n",
    "data['skills'] = skills_list\n",
    "#data['skills'].value_counts().plot('bar')\n",
    "print(data['skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bubble of average salary by state with the size based on the number of jobs; repeat for cities\n",
    "def bubble(x,y,z,titles, xes, yes):\n",
    "    #plt.scatter(x, y, s=z*4000, c=\"red\", alpha=0.4)\n",
    "    plt.scatter(x, y, s=z*4000, c=\"green\", alpha=0.4, linewidth=6)\n",
    "    plt.xlabel(xes)\n",
    "    plt.ylabel(yes)\n",
    "    plt.title(titles, loc=\"left\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble(data['category'], data['state'], data['salary_offered'], \"Title\", \"XLabel\", \"Ylabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bubble of average salary by cities with the size based on the number of job\n",
    "bubble(data['category'], data['city'], data['salary_offered'], \"Title\", \"XLabel\", \"Ylabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter category and salary\n",
    "sns.scatterplot(x='category', y='salary_offered', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement for all.\n",
    "def histogram(field, title, xlabel, ylabel):\n",
    "    ax = data[field].value_counts().nlargest(10).plot(kind='bar', title =title, figsize=(15, 10), legend=True, fontsize=12)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstabs(sidea, sideb):\n",
    "    clarity_color_table = pd.crosstab(index=sidea, \n",
    "                          columns=sideb)\n",
    "\n",
    "    \n",
    "    clarity_color_table.plot(kind=\"bar\", \n",
    "                 figsize=(8,8),\n",
    "                 stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eda\n",
    "#count of categories-bar\n",
    "#count of companies-bar\n",
    "#count of citys-bubble density\n",
    "#count of states-bubble density\n",
    "#count of job type-bar\n",
    "#salary scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar vis\n",
    "'''\n",
    "ax = data.company_name.value_counts().nlargest(10).plot(kind='bar', title =\"Most Hiring Companies\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax.set_xlabel(\"Company Name\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of postings\", fontsize=12)\n",
    "plt.show()\n",
    "'''\n",
    "histogram(company_name,\"Companies Hiring the Most\", \"Company Name\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar vis 2\n",
    "ax3 = data.job_title.value_counts().nlargest(10).plot(kind='bar', title =\"Job Categories\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax3.set_xlabel(\"Job Category\", fontsize=12)\n",
    "ax3.set_ylabel(\"Number of postings\", fontsize=12)\n",
    "plt.show()\n",
    "histogram(job_title,\"Most Job Title\", \"Job Title\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar vis 3\n",
    "ax2 = data.state.value_counts().nlargest(10).plot(kind='bar', title =\"Highest States\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax2.set_xlabel(\"States\", fontsize=12)\n",
    "ax2.set_ylabel(\"Number of postings\", fontsize=12)\n",
    "plt.show()\n",
    "histogram(state,\"States with Most opportunities\", \"State\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = data[\"city\"].value_counts().nlargest(20).plot(kind='bar', title =\"Highest Cities\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax2.set_xlabel(\"Cities\", fontsize=12)\n",
    "ax2.set_ylabel(\"Number of postings\", fontsize=12)\n",
    "plt.show()\n",
    "histogram(city,\"Companies Hiring the Most\", \"Company Name\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bubble chart for skills and \n",
    "ax5 = data[\"category\"].value_counts().nlargest(5).plot(kind='bar', title =\"Highest Cities\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax5.set_xlabel(\"Cities\", fontsize=12)\n",
    "ax5.set_ylabel(\"Number of postings\", fontsize=12)\n",
    "plt.show()\n",
    "histogram(category,\"Most Common Industries\", \"Industry\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#density plots 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def mapping(datapoint):\n",
    "    df=datapoint['state'].value_counts().to_frame()\n",
    "    #print(df)\n",
    "    fig = go.Figure(data=go.Choropleth(\n",
    "        locations=data['state'], # Spatial coordinates\n",
    "        z = df['state'].astype(float), # Data to be color-coded\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = 'picnic',\n",
    "\n",
    "        colorbar_title = \"Millions USD\",\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text = 'number job postings by state',\n",
    "        geo_scope='usa', # limite map scope to USA\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "#color is off; try here https://stackoverflow.com/questions/53685906/choropleth-map-in-plotly-colours-not-showing-correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping 3 title by city \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_us_cities.csv')\n",
    "#df.head()\n",
    "\n",
    "#df['text'] = df['name'] + '<br>Population ' + (df['pop']/1e6).astype(str)+' million'\n",
    "limits = [(0,2),(3,10),(11,20),(21,50),(50,3000)]\n",
    "colors = [\"royalblue\",\"crimson\",\"lightseagreen\",\"orange\",\"lightgrey\"]\n",
    "cities = []\n",
    "scale = 5000\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(limits)):\n",
    "    lim = limits[i]\n",
    "    df_sub = data[lim[0]:lim[1]]\n",
    "    fig.add_trace(go.Scattergeo(\n",
    "        locationmode = 'USA-states',\n",
    "        lon = df_sub['long'],\n",
    "        lat = df_sub['lat'],\n",
    "        text = df_sub['city'],\n",
    "        marker = dict(\n",
    "            size = df_sub['pop']/scale,\n",
    "            color = colors[i],\n",
    "            line_color='rgb(40,40,40)',\n",
    "            line_width=0.5,\n",
    "            sizemode = 'area'\n",
    "        ),\n",
    "        name = '{0} - {1}'.format(lim[0],lim[1])))\n",
    "\n",
    "fig.update_layout(\n",
    "        title_text = '2014 US city populations<br>(Click legend to toggle traces)',\n",
    "        showlegend = True,\n",
    "        geo = dict(\n",
    "            scope = 'usa',\n",
    "            landcolor = 'rgb(217, 217, 217)',\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WOW CALIFORNIA IS OVER REPRESENTED!, lets try this again without ca\n",
    "data2 = data.copy()\n",
    "indexNames = data2[data2['state'] == \"CA\" ].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "data2.drop(indexNames , inplace=True)\n",
    "def histogram2(field, title, xlabel, ylabel):\n",
    "    ax = data2[field].value_counts().nlargest(10).plot(kind='bar', title =title, figsize=(15, 10), legend=True, fontsize=12)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remix\n",
    "histogram2(company_name,\"Companies Hiring the Most\", \"Company Name\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram2(category,\"Most Common Industries\", \"Industry\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram2(city,\"Companies Hiring the Most\", \"Company Name\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram3(state,\"States with Most opportunities\", \"State\", \"Number of Postings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble(data2['category'], data2['state'], data2['salary_offered'], \"Title\", \"XLabel\", \"Ylabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble(data2['category'], data2['city'], data2['salary_offered'], \"Title\", \"XLabel\", \"Ylabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='category', y='salary_offered', data=data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
